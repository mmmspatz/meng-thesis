\newcommand{\uvec}[1]{\bm{\hat{#1}}}
\newcommand{\bvec}[1]{\bm{\vec{#1}}}

\chapter{Background}
Magnetic resonance imaging is, as the name suggests, enabled by the phenomenon of magnetic resonance.

\section{Origin of MR signal}

\subsection{Nuclear Spins}
Spin is a quantum mechanical property that describes a particle's intrinsic angular momentum. Atoms with an odd
number of protons or neutrons possess net nuclear spin, and therefore have mutually aligned angular momentum $\bvec{S}$
and magnetic dipole moment $\bvec{\mu}= \gamma \bvec{S}$, where $\gamma$ is the gyromagnetic ratio: a known constant
defined for every nucleus. Hydrogen (\ce{^{1}_{1}H}) is such an atom, having one proton and no neutrons. Along a given
axis, hydrogen spins are quantized to $\pm \frac{\hbar}2$.  Therefore, hydrogen dipole moments are likewise quantized to
$\pm \gamma \frac{\hbar}{2}$ (eq. \ref{eq:dipole}).

\begin{equation}\label{eq:dipole}
    \mu = \pm \gamma \frac{\hbar}{2}
\end{equation}

\subsection{Spins in the Presence of External Magnetic Fields}
In the presence of a strong polarizing field pointing in the $\uvec{k}$ direction and with magnitude $B_0$, the
potential energy of a spin with dipole moment $\bvec{\mu}$ is the dot product between the two vectors (eq.
\ref{eq:spin_energy}). Because $\mu$ is quantized, there is a gap $\Delta E$ between realizable energy states (eq.
\ref{eq:delta_E}).

\begin{equation}\label{eq:spin_energy}
    E = - \bvec{\mu} \cdot \bvec{B_0}
\end{equation}

\begin{equation}\label{eq:delta_E}
    \Delta E = \gamma \hbar B_0
\end{equation}

\subsubsection{Polarization}
Spins tend to settle in the low energy state, pointing in the direction of $\bvec{B_0}$. However, at room temperature,
thermal energy vastly exceeds the energy gap between the two states, and the ratio of spins aligned with $\bvec{B_0}$
($n_+$) to those anti aligned ($n_-$) is described by the Boltzmann distribution in eq. \ref{eq:boltzmann}. For hydrogen
($\gamma = \frac{42.58}{2\pi} \frac{MHz}{T}$) at room temperature ($T=273 K$) at a field strength of $3T$, $\Delta E =
5.283 \times 10^{-7} eV$, and $\frac{n_-}{n_+} \approx (1 - 2.25 \times 10^{-5})$. This relatively tiny fraction of
excess spin polarization is the source of the NMR signal. Luckily, there are $3.3428 \times 10^{23}$ protons in a gram
of water, resulting in $7.5 \times 10^{18}$ aligned spins per gram under the previously stated conditions. Since living
things tend to contain mostly water, the proposal of MRI is still promising.

\begin{equation}\label{eq:boltzmann}
    \frac{n_-}{n_+} = \exp(-\frac{\Delta E}{k T}) = \exp(-\frac{\gamma \hbar B_0}{k T})
\end{equation}

In a large population of spins, the net magnetic dipole moment per unit volume is termed $\bvec{M}$. In equilibrium, it
is the product of the volumetric spin density $N$, the magnitude of a single spin dipole moment $\mu$, and the excess
fraction of aligned spins. It points in the same direction as $\bvec{B_0}$ and has magnitude $M_0$. Using the first two
terms of a taylor series expansion of the Boltzmann distribution, we can approximate $M_0$ as eq. \ref{eq:M}.

\begin{equation}\label{eq:M}
    M_0 = N \cdot \mu \cdot (1-\exp(-\frac{\Delta E}{k T})) \approx \frac{N \gamma^2 \hbar^2 B_0}{2 k T}
\end{equation}

\subsection{Spin Dynamics}
In equilibrium, $\bvec{M}$ comes to point in the direction $\bvec{B_0}$ with magnitude $M_0$. But the next step will be
to tip $\bvec{M}$ off of the $z$ axis so that it has a component in the $x$-$y$ plane. The observed behavior will then
be time varying.

\subsubsection{Precession}
A single magnetic dipole $\bvec{\mu}$ with mutually aligned angular momentum $\bvec{S}$ placed in an external magnetic
field $\bvec{B}$ will experience a torque $\bvec{\mu} \times \bvec{B}$. Multiplying this torque by $\gamma$ gives an
expression for the time rate of change of $\bvec{\mu}$, eq. \ref{eq:dipole_precession}. Eq. \ref{eq:dipole_precession}
shows $\bvec{\mu}$ moving in a direction perpendicular to both itself and $\bvec{B}$, i.e. precessing about $\bvec{B}$.
The frequency of this precession is $\omega_L$ in eq. \ref{eq:precession_freq}.

\begin{equation}\label{eq:dipole_precession}
    \frac{d \bvec{\mu}}{dt} = \bvec{\mu} \times \gamma \bvec{B}
\end{equation}

\begin{equation}\label{eq:precession_freq}
    \omega_L = \gamma \cdot B
\end{equation}

A population of dipole moments precessing in synchrony gives a net magnetization $\bvec{M}$ that also precesses at
$\omega_L$.

\subsubsection{Longitudinal Relaxation}
Define the component of $\bvec{M}$ that is parallel to $\bvec{B_0}$ as $\bvec{M_z}$. In equilibrium $|\bvec{M_z}| =
M_0$, but immediately following the tipping of $\bvec{M}$ into the $x$-$y$ plane by an angle $\alpha$ at time $t=0$,
$\bvec{M_z}$ is reduced to a value shown in eq. \ref{eq:mz_postflip}.

\begin{equation}\label{eq:mz_postflip}
    \bvec{M_z}(t=0+) = \cos(\alpha) \cdot \bvec{M_z}(0-)
\end{equation}

$\bvec{M_z}$ then begins to exponentially recover to its equilibrium magnitude of $M_0$. The time constant associated
with this longitudinal recovery is termed $T_1$. $T_1$ is dependent on the tissue or material being imaged, but also has
a positive dependence on $B_0$ field strength.

\begin{equation}\label{eq:t1_decay}
    \bvec{M_{z}}(t) = \uvec{k} M_0 + (\bvec{M_{z}}(0+) - \uvec{k} M_0) \cdot \exp(-\frac{t}{T_1})
\end{equation}

\subsubsection{Transverse Relaxation}
Define the component of $\bvec{M}$ that is perpendicular to $\bvec{B_0}$ as $\bvec{M_{xy}}$. In equilibrium,
$\bvec{M_{xy}} = 0$.  Immediately following the tipping of $\bvec{M}$ into the $x$-$y$ plane by an angle $\alpha$ at
time $t=0$, $\bvec{M_{xy}}$ is as shown in eq. \ref{eq:mxy_postflip}. Individual spins begin to dephase as soon as they
are tipped into the $x$-$y$ plane, and so the net transverse magnetization $\bvec{M_{xy}}$ experiences exponential
decay, as shown in eq. \ref{eq:t2_decay}. The time constant associated with this transverse decay is termed $T_2$, and
is a property of the tissue or material being imaged.

\begin{equation}\label{eq:mxy_postflip}
    \bvec{M_{xy}}(t=0+) = \uvec{i}\sin(\alpha) \cdot |\bvec{M_z}(0-)|
\end{equation}

\begin{equation}\label{eq:t2_decay}
    \bvec{M_{xy}}(t) = \bvec{M_{xy}}(0+) \cdot \exp(-\frac{t}{T_2})
\end{equation}

\subsection{Bloch Equation}
Assembled together, the spin dynamics described above form the Bloch equation, shown in eq. \ref{eq:bloch}. The complete
Bloch equation describes the behavior of spins in a generalized external magnetic field $\bvec{B}$ that is the sum of
the main field $B_0$, the RF field $B_1$, and the linearly varying gradient fields $G$. 

\begin{equation}\label{eq:bloch}
    \frac{d \bvec{M}}{dt} = \bvec{M} \times \gamma \bvec{B} - \frac{M_x \uvec{i} + M_y \uvec{j}}{T_2} - \frac{(M_z - M_0)
    \uvec{k}}{T_1}
\end{equation}

\section{Signal Equation}
The NMR signal arises from the precessing transverse component of the magnetization vector. As we begin to focus solely
on $\bvec{M_{xy}}$, I will follow the convention used by Nishimura \cite{nishimura} and define a new variable $M$ that
represents the transverse magnetization as a function of location and time with single complex number.

\begin{equation}\label{eq:M_complex}
    M(\bvec{r},t) \equiv |\bvec{M_x}| + j |\bvec{M_y}|
\end{equation}

\subsection{Signal Detection Through Faraday Induction}
The wire loop antenna is the most commonly used receive element in clinical MRI. It works by directly coupling to the
field produced by the transverse magnetization of the sample under test. The precessing magnetization produces a time
varying magnetic flux piercing the surface defined by the loop, which induces a voltage $\epsilon$ around the loop
through Faraday induction.

\begin{equation}\label{eq:faraday_induction}
    \epsilon = - \frac{d \Phi_B}{dt} = -\frac{d}{dt} \iint_A B(\bvec{r},t) dA
\end{equation}

A loop antenna has spatially varying sensitivity to spins. If a unit current through the loop produces a field
$\bvec{B_1}$ at location $\bvec{r}$ in the sample, then magnetization $\bvec{M}$ at that location produces a flux of
$\bvec{B_1} \cdot \bvec{M}$ through the loop.  \cite{Hoult1979}. Citing linearity, we can find an expression for the
total voltage induced around the loop by summing the individual contributions from every location in the sample volume.

\begin{equation}\label{eq:reciprocity}
    \epsilon = -\frac{d}{dt} \iiint_V \bvec{B_1}(\bvec{r}) \cdot \bvec{M}(\bvec{r}) d\bvec{r}
\end{equation}

The voltage around the loop depends on the time derivative of a volume integral over the entire sample volume. At this
point, it is clear why only the precessing transverse magnetization is of interest for signal detection. Substituting
our complex variable $M$ in eq. \ref{eq:reciprocity}, and replacing $\bvec{B_1}$ with a more general complex sensitivity
function $C(\bvec{r})$ that also accounts for spatially dependent signal phase, we get the beginnings of the signal
equation

\begin{equation}\label{eq:signal_1}
    \epsilon = -\frac{d}{dt} \iiint_V C(\bvec{r}) \cdot M(\bvec{r},t) d\bvec{r}
\end{equation}

\section{Fourier Encoding}

\subsection{Gradient Fields}
Spatial encoding in traditional MRI is achieved by applying spatially varying gradient fields on top of the main field,
as shown in eq. \ref{eq:gradients}. Just like $\bvec{B_0}$, $\bvec{G}$ points in the $\uvec{k}$ direction. Unlike
$\bvec{B_0}$, $\bvec{G}$ varies as a function of space and time.

\begin{equation}\label{eq:gradients}
    \bvec{B} = (B_0 + G(\bvec{r},t))\uvec{k}
\end{equation}

After an initial flip resulting in a spatial magnetization distribution $M(\bvec{r},t=0)$, spins begin precess under the
influence of $G$, as described in \ref{eq:phase_enc}. After a time $t$, spins at a location $\bvec{r}$ have accrued
excess phase in proportion to the time integral of $G(\bvec{r},t)$.

\begin{equation}\label{eq:phase_enc}
    M(\bvec{r},t) = M(\bvec{r},t=0) e^{-j \gamma B_0 t} exp(-j \gamma \int_0^t G(\bvec{r},\tau) d \tau)
\end{equation}

Plugging this expression for $M$ into eq. \ref{eq:signal_1}, making the assumption that $B_0 >> G$ so that all spins
precess at a frequency of approximately $\omega_L = \gamma B_0$, and dividing by $e^{-j \omega_L t}$ to downconvert to
baseband, we extend the signal equation to describe the effect of gradient fields.

\begin{equation}\label{signal_2}
    s(t) = - j \omega_L \iiint_V C(\bvec{r}) M(\bvec{r},t=0) exp(-j \gamma \int_0^t G(\bvec{r},\tau)
    d\tau)
\end{equation}

If we constrain ourselves to linear encoding gradients, such that

\begin{equation}\label{linear_gradient}
    G(\bvec{r}=x\uvec{i} + y\uvec{j} + z\uvec{k},t) = G_x(t) x + G_x(t) y + G_z(t) z 
\end{equation}

and then define three $k$ variables to descbibe the history of $G$ along each axis:

\begin{equation}\label{k_space}
    \begin{aligned}
        k_x &= \frac{\gamma}{2\pi} \int_0^t G_x(\tau) d\tau\\
        k_y &= \frac{\gamma}{2\pi} \int_0^t G_y(\tau) d\tau\\
        k_z &= \frac{\gamma}{2\pi} \int_0^t G_z(\tau) d\tau
    \end{aligned}
\end{equation}

we come up with the final form of the signal equation:

\begin{equation}\label{eq:signal_3}
    s(t) = - j \omega_L \iiint_V C(\bvec{r}) M(\bvec{r},t=0) e^{-j k_x x} e^{-j k_y y} e^{-j k_z z} dV 
\end{equation}

\subsection{The Fourier Transform}
The Fourier transform breaks down a function into its individual frequency components by taking inner products of that
function with complex exponentials. Its one dimensional form is shown in eq. \ref{eq:fourier_transform}.

\begin{equation}\label{eq:fourier_transform}
    F(k_x) = \int_{-\infty}^{\infty} f(x)e^{-j2\pi k_x x} dx
\end{equation}

Strikingly, eqs. \ref{eq:signal_3} and \ref{eq:fourier_transform} look extremely similar. The effect of our carefully
chosen linear gradient fields has been to set up a physical three dimensional Fourier transform, where we take the inner
product of $M$ with a complex exponential whose phase has linear dependence on space. Manipulation of $G(t)$ allows us
to visit and sample arbitrary coordinates $(k_x,k_y,k_z)$ in so called "k-space".  By collecting k-space points on a
cartesian grid and obeying certain sampling criteria, we can collect data that directly represents a spatial Fourier
transform of the sample under test, weighted by $C(\bvec{r})$ and $M(\bvec{r},t=0+)$.

\section{Noise in MRI}
\subsection{Thermal Noise}
The signals involved in MRI are very weak, and extreme care is taken to avoid and minimize all possible noise
sources. Thermal noise arising inside the body is, however, unavoidable. When a perfectly conducting wire loop is
brought near an object with finite conductivity, inductive coupling causes a transformed resistance $R_{LOAD}$ to appear
in the loop. $R_{LOAD}$ depends on the geometry and conductivity of the object that is loading the loop, as well as the
strength of the coupling. If $R_{LOAD}$ is measurable, it can be used to quantify the thermal noise that will be induced
by the sample.

\begin{equation}\label{eq:thermal_noise}
    \bar{e_n^2} = 4 k T_{LOAD} R_{LOAD} \Delta f
\end{equation}

\subsubsection{Estimating $R_{LOAD}$}

A current $I$ flowing in the loop creates a spatially varying magnetic field $\bvec{B_1}(\bvec{r})$ in the sample below it. If $I$
is sinusoidal, then the changing $\bvec{B_1}$ will create an associated electric field $\bvec{E}$ according to Faraday's
law of induction.

\begin{equation}\label{eq:differential_faraday}
    \nabla \times \bvec{E}(\bvec{r}) = - \frac{\partial \bvec{B_1}(\bvec{r})}{\partial t}
\end{equation}

If we can solve for this $\bvec{E}$, and if we know the conductivity of the sample, we can determine the power
deposition in the sample and model it by $R_{LOAD}$.

\begin{equation}\label{eq:P_sample}
    P_{SAMPLE} = \frac{1}{2} \iiint_V \sigma |\bvec{E}(\bvec{r})|^2 d\bvec{r}
\end{equation} 

\begin{equation}
    R_{LOAD} = \frac{P_{SAMPLE}}{\sqrt{I}} 
\end{equation}

\subsection{Preamp Noise}
Of the noise sources that we can control, the first amplifier in the signal processing chain is most critical. By
faithfully amplifying the weak NMR signal early, the relative impact of noise injected by further transmission and
processing steps is lessened. Here, I follow chapter 10.6 of \cite{lee2004} to derive an optimal source admittance that
optimizes the noise performance of an amplifier.

\subsubsection{Noise Factor}
Noise factor (denoted by $F$) is a parameter that characterizes the noise performance of an amplifier (or mixer, or any other signal
processing block).  It is defined as:

\begin{equation}\label{eq:noise_factor}
    F = \frac{\text{Total Output Noise Power}}{\text{Output Noise Power Due To Source}}
\end{equation}

In systems consisting of multiple blocks (preamplifier, analog filter, mixer, ADC..) it becomes useful to refer to the
logarithm of $F$, so that the noise contribution of cascaded blocks can be represented as a sum. This logarithmic
parameter is called noise figure:

\begin{equation}\label{eq:noise_figure}
    NF = 20 \log_{10}(F)
\end{equation}

\subsubsection{Two Port Noise Model}

A two port model of a noisy amplifier is shown in figure \ref{fig:2port_noise}. The noise behavior of the amplifier is
completely characterized by two input referenced noise sources: a voltage source with mean value $\bar{e}_n$, and a
current source with with mean value $\bar{i}_n$.

\begin{figure}
    \centering
    \input{figures/2port_noise.pdf_tex}
    \caption{Two port model of a noisy preamp connected to a noisy source.}
    \label{fig:2port_noise}
\end{figure}

Connected to the input of the amplifier is a noise current source with input admittance $Y_S$ and mean value
$\bar{i}_s$. The noise current is assumed to arise purely from the real part of $Y_S$, so the two are related by eq.
\ref{eq:source_admittance}

\begin{equation}\label{eq:source_admittance}
    Re(Y_S) = G_S = \frac{\bar{i_s^2}}{4kT\Delta f}
\end{equation}

We assume that $\bar{i_s}$ statistically independent from $\bar{e_n}$ and $\bar{i_n}$, since they arise inside of
physically distinct devices. Since $\bar{e_n}$ and $\bar{i_n}$ may arise inside of a single transistor, they cannot be
assumed to be uncorrelated.

Using the parameters of this model, we can begin to calculate the amplifier's noise figure. Since we only need to find
the ratio between total noise power and source derived noise power, not the actual values themselves, we can use the
short cut that output power will be proportional to short circuit mean square input current in both cases.

\begin{equation}\label{eq:2port_noisefactor}
    F = \frac{\overline{|i_s + i_n + Y_S e_n|^2}}{\bar{i_s^2}}
\end{equation}

If we expand the squared term in the numerator, we can get rid of cross terms between uncorrelated variables:

\begin{equation}\label{eq:2port_noisefactor_2}
    F = \frac{\bar{i_s^2} + \overline{|i_n + Y_S e_n|^2}}{\bar{i_s^2}}
\end{equation}

The next step is to break up $i_n$ into two parts: $i_{n_u}$ which is uncorrelated with $e_n$, and $i_{n_c}$ which is
correlated to $e_n$. The correlation coefficient takes the form of a complex transadmittance $Y_C$, as it is a ratio between
a current and a voltage.

\begin{equation}\label{eq:cor_uncoor}
    i_n = i_{n_u} + i_{n_c} = i_{n_u} + Y_C e_n
\end{equation}

Making this substitution and again removing uncorrelated cross terms, eq. \ref{eq:2port_noisefactor_2} becomes:

\begin{equation}\label{eq:2port_noisefactor_3}
    F = 1 + \frac{\bar{i_u^2} + |Y_S + Y_C|^2 \bar{e_n^2}}{\bar{i_s^2}}
\end{equation}

\subsubsection{Admittance, Conductivity, and Susceptibility}
Before beginning the next section, recall that just as a complex impedance $Z$ can be decomposed into its real
resistance $R$ and imaginary reactance $X$, a complex admittance $Y$ may be decomposed into a conductivity $G$ and
susceptibility $B$:

\begin{equation}\label{eq:admittance}
    \begin{aligned}
        Z &= R + jX\\
        Y &= G + jB
    \end{aligned}
\end{equation}

\subsubsection{Optimal Source Impedance}
There is an optimal value $Y_S$ that will minimize $F$. All that's left to do in finding it is to set up
\ref{eq:2port_noisefactor} so that we can take derivatives with respect to $Y_S$ and set them equal to zero.

Replace the admittances $Y_S$ and $Y_C$ with the corresponding conductivities and susceptibilities, then substitute
$\bar{i_s^2} = G_S 4kT\Delta f$ in the denominator. eq. \ref{eq:2port_noisefactor_3} becomes:

\begin{equation}\label{eq:2port_noisefactor_4}
    F = 1 + \frac{\bar{i_u^2} + \big[(G_C+G_S)^2 + (B_C+B_S)^2\big] \bar{e_n^2}}{4kT \Delta f G_s}
\end{equation}

Minimize $F$ with respect to $B_S$:

\begin{equation}\label{eq:partial_B_S}
    \frac{\partial F}{\partial B_S} = \frac{(2 B_C + 2 B_S) \bar{e_n^2}}{4kT\Delta f G_S} \implies B_{S_{OPT}} = -B_C
\end{equation}

Then, minimize $F$ with respect to $G_S$ and plug in $B_{S_{OPT}}$:

\begin{equation}\label{eq:partial_G_S}
    \frac{\partial F}{\partial G_S} = -\frac{\bar{i_u^2} + \bar{e_n^2} \big[{G_C}^2 + (B_C+B_S)^2 \big]}{4kT\Delta f
    {G_S}^2} + \frac{\bar{e_n^2}}{4 kT\Delta f} \implies G_{S_{OPT}} = \sqrt{\frac{\bar{i_u^2}}{\bar{e_n^2}} + G_C^2}
\end{equation}

We have found our optimal source impance $Y_{S_{OPT}}$.

\begin{equation}\label{eq:y_opt}
    Y_{S_{OPT}} =  \sqrt{\frac{\bar{i_u^2}}{\bar{e_n^2}} + G_C^2} - j B_C
\end{equation}
